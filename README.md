# ELA AI - Econometrics Learning Assistant üéì

![ELA AI Banner](public/ela_banner.png)

## üìñ Description

ELA AI est un assistant d'apprentissage intelligent sp√©cialis√© en √©conom√©trie, d√©velopp√© avec Chainlit et LangChain. Il combine deux approches puissantes :
1.  **RAG (Retrieval-Augmented Generation)** : Pour r√©pondre aux questions th√©oriques en se basant exclusivement sur des supports de cours LaTeX.
2.  **Vision par Ordinateur** : Pour analyser et expliquer des graphiques, tableaux ou √©quations manuscrites via des mod√®les multimodaux.

Le projet est con√ßu pour la production avec une architecture conteneuris√©e (**Docker**) et une base de donn√©es persistante (**PostgreSQL**).

### ‚ú® Fonctionnalit√©s principales

- üß† **RAG Expert** : Recherche hybride (BM25 + S√©mantique) sourc√©e exclusivement dans vos documents.
- üëÅÔ∏è **Vision IA** : Analyse d'images (courbes, matrices, scans) via Llama 4 Scout / Llama 3.2 Vision.
- üìÇ **Galerie "Mes Contenus"** : Espace d√©di√© pour retrouver toutes les images et graphiques envoy√©s.
- üíæ **Persistance SQL** : Historique des conversations et feedbacks stock√©s durablement dans PostgreSQL.
- ‚ö° **Reranking intelligent** : Utilisation de FlashRank pour optimiser la pertinence des r√©sultats.
- üîê **Authentification** : Syst√®me multi-utilisateurs (√âtudiant / Superviseur) s√©curis√©.
- üìê **Support LaTeX** : Affichage natif des formules math√©matiques.

---

## üöÄ Installation & D√©ploiement

Vous avez deux modes d'installation : **Production (Docker)** ou **D√©veloppement (Local)**.

### Pr√©requis

- Git
- Une cl√© API Groq (gratuite sur [console.groq.com](https://console.groq.com))
- **Mode Docker** : Docker Desktop & Docker Compose
- **Mode Local** : Python 3.11+ et PostgreSQL install√© localement

### Option A : D√©ploiement Docker (Recommand√©)

C'est la m√©thode la plus simple pour lancer l'application avec sa base de donn√©es.

1.  **Cloner le repository**
    ```bash
    git clone [https://github.com/varennes-ecofin/ela-ai-master.git](https://github.com/varennes-ecofin/ela-ai-master.git)
    cd ela-ai-master
    ```

2.  **Configuration**
    Cr√©ez un fichier `.env` √† la racine :
    ```ini
    GROQ_API_KEY=gsk_votre_cle_ici
    CHAINLIT_AUTH_SECRET=votre_secret_aleatoire
    ELA_AUTH_DATA=etudiant:password,supervisor:password
    
    # Configuration Docker (ne pas toucher pour le mode Docker)
    DATABASE_URL=postgresql+asyncpg://chainlit_user:securepassword@db:5432/chainlit_db
    ```

3.  **Lancer les services**
    ```bash
    docker compose up -d --build
    ```

4.  **Initialiser la Base de Donn√©es (Premier lancement uniquement)**
    ```bash
    docker compose exec db psql -U chainlit_user -d chainlit_db -c "
    CREATE TABLE IF NOT EXISTS users (id UUID PRIMARY KEY, identifier TEXT UNIQUE, \"createdAt\" TEXT, metadata JSONB);
    CREATE TABLE IF NOT EXISTS threads (id UUID PRIMARY KEY, name TEXT, \"createdAt\" TEXT, \"userId\" UUID REFERENCES users(id), \"userIdentifier\" TEXT, tags TEXT[], metadata JSONB);
    CREATE TABLE IF NOT EXISTS steps (id UUID PRIMARY KEY, name TEXT, type TEXT, \"threadId\" UUID REFERENCES threads(id), \"parentId\" UUID, \"disableFeedback\" BOOLEAN, streaming BOOLEAN, \"waitForAnswer\" BOOLEAN, \"isError\" BOOLEAN, metadata JSONB, tags TEXT[], input TEXT, output TEXT, \"createdAt\" TEXT, start TEXT, \"end\" TEXT, generation JSONB, \"showInput\" TEXT, language TEXT, indent INT, \"defaultOpen\" BOOLEAN);
    CREATE TABLE IF NOT EXISTS elements (id UUID PRIMARY KEY, \"threadId\" UUID REFERENCES threads(id), type TEXT, url TEXT, \"chainlitKey\" TEXT, name TEXT, display TEXT, \"objectKey\" TEXT, size TEXT, page INT, language TEXT, \"forId\" UUID, mime TEXT, props JSONB);
    CREATE TABLE IF NOT EXISTS feedbacks (id UUID PRIMARY KEY, \"forId\" UUID REFERENCES steps(id), value INT, comment TEXT);
    INSERT INTO users (id, identifier, \"createdAt\") VALUES (gen_random_uuid(), 'etudiant', NOW()) ON CONFLICT (identifier) DO NOTHING;
    "
    ```

L'application est accessible sur : **http://localhost:80** (ou l'IP de votre serveur).

### Option B : Installation Locale (D√©veloppement)

1.  **Environnement virtuel**
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # ou .venv\Scripts\activate sur Windows
    pip install -r requirements.txt
    ```

2.  **Configuration .env**
    Attention √† l'URL de la base de donn√©es qui doit pointer vers votre localhost :
    ```ini
    DATABASE_URL=postgresql+asyncpg://chainlit_user:securepassword@localhost:5432/chainlit_db
    ```

3.  **Lancer l'application**
    ```bash
    chainlit run app.py -w
    ```

---

## üìö Configuration de la base de connaissances

Pour que le RAG fonctionne, vous devez ing√©rer vos cours.

1.  **Pr√©parer vos fichiers**
    Placez vos fichiers `.tex` dans le dossier `./latex/`.

2.  **Lancer l'ingestion**
    ```bash
    python ingest.py
    ```
    *Cela va g√©n√©rer la base vectorielle dans le dossier `./chroma_db/`.*

---

## üéÆ Utilisation

### Identifiants par d√©faut

| Utilisateur | Mot de passe | R√¥le |
|-------------|--------------|------|
| `etudiant` | `password` | Acc√®s standard + Galerie |
| `supervisor` | `password` | Acc√®s complet (futur admin) |

*Ces identifiants sont configurables dans la variable `ELA_AUTH_DATA` du fichier `.env`.*

### Commandes Chat
- **Upload d'image** : Glissez-d√©posez une image pour qu'ELA l'analyse.
- **Bouton "Ma Galerie"** : Cr√©e une conversation affichant l'historique de vos images.

---

## üèóÔ∏è Architecture du projet

```text
ela-ai-master/
‚îú‚îÄ‚îÄ .files_ela/             # Stockage physique des images (Persistance Docker)
‚îú‚îÄ‚îÄ chroma_db/              # Base vectorielle (Embeddings des cours)
‚îú‚îÄ‚îÄ latex/                  # Sources .tex des cours
‚îú‚îÄ‚îÄ public/                 # Assets (Logos, ic√¥nes)
‚îú‚îÄ‚îÄ app.py                  # Application principale (Chainlit + DB + Galerie)
‚îú‚îÄ‚îÄ main_ela.py             # Cerveau IA (LangChain, Vision, RAG)
‚îú‚îÄ‚îÄ ingest.py               # Script d'ingestion des donn√©es
‚îú‚îÄ‚îÄ docker-compose.yml      # Orchestration Docker
‚îú‚îÄ‚îÄ Dockerfile              # Image syst√®me
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances Python
‚îî‚îÄ‚îÄ .env                    # Secrets (Non commit√©)

---

## üîß Configuration avanc√©e

### Modifier le mod√®le LLM

Dans `main_ela.py`, vous pouvez ajuster le mod√®le utilis√© :

```python
# Mod√®le Vision & Texte
self.llm = ChatGroq(
    model="llama-3.2-90b-vision-preview", # ou "llama-4-scout-..."
    temperature=0.0,
    max_tokens=2048
)

```

### Stockage des fichiers

Les images upload√©es sont stock√©es localement via la classe `LocalStorageClient` dans `app.py`. En production Docker, ce dossier est mont√© via un volume pour ne pas perdre les donn√©es au red√©marrage.

---

## üêõ R√©solution de probl√®mes

### Erreur "getaddrinfo failed" (Docker vs Local)

Si vous passez du serveur √† votre PC local, n'oubliez pas de changer `DATABASE_URL` dans le `.env` :

* Serveur Docker : `@db:5432`
* PC Local : `@localhost:5432`

### Erreur d'affichage des ic√¥nes (Starters)

Assurez-vous que le dossier `public` est bien mont√© dans le `docker-compose.yml` et videz le cache de votre navigateur.

---

## üìä Stack technique

| Composant | Technologie |
| --- | --- |
| **Frontend/Backend** | Chainlit 2.9.6 |
| **LLM Engine** | Groq (Llama 3.2 Vision / Llama 3.3) |
| **Database** | PostgreSQL 15 + AsyncPG |
| **Vector Store** | ChromaDB |
| **Orchestration** | Docker Compose |
| **Framework IA** | LangChain |

---

## üìù License & Contact

Ce projet est d√©velopp√© dans un cadre p√©dagogique.
¬© 2026 - Gilles de Truchis

**GitHub** : [github.com/varennes-ecofin](https://github.com/varennes-ecofin)
